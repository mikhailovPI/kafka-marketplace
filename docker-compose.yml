x-kafka-common-env: &kafka-common-env
  KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
  KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
  # SSL settings
  KAFKA_SSL_KEYSTORE_TYPE: JKS
  KAFKA_SSL_TRUSTSTORE_TYPE: JKS
  KAFKA_SSL_TRUSTSTORE_PASSWORD: your-password
  KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
  # SASL settings
  KAFKA_ZOOKEEPER_SASL_CLIENT: 'true'
  KAFKA_ZOOKEEPER_SET_ACL: 'true'
  KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
  KAFKA_SASL_MECHANISM_CONTROLLER_PROTOCOL: PLAIN
  KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
  KAFKA_INTER_BROKER_LISTENER_NAME: SASL_SSL
  KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
  KAFKA_SUPER_USERS: User:admin
  KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/config/kafka_server_jaas.conf"
  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: SASL_SSL:SASL_SSL,OUTBOUND:SASL_SSL
  # Memory settings - ДОБАВЛЕНО
  KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
services:
  # Основной кластер
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.4
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - ./credentials/zookeeper.sasl.jaas.conf:/etc/zookeeper/secrets/zookeeper.sasl.jaas.conf
      - ./credentials/kafka-0-creds:/etc/zookeeper/secrets
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: >-
        -Djava.security.auth.login.config=/etc/zookeeper/secrets/zookeeper.sasl.jaas.conf
        -Dzookeeper.authProvider.sasl=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
        -Dzookeeper.allowSaslFailedClients=false
        -Dzookeeper.requireClientAuthScheme=sasl
    networks:
      - kafka-connect-network

  kafka-0:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-0
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "19092:19092"
    volumes:
      - ./credentials/kafka-0-creds:/etc/kafka/secrets
      - ./credentials/kafka_server_jaas.conf:/etc/kafka/config/kafka_server_jaas.conf
      - ./credentials/admin.properties:/etc/kafka/secrets/admin.properties
    environment:
      <<: *kafka-common-env
      KAFKA_BROKER_ID: 0
      KAFKA_ADVERTISED_LISTENERS: SASL_SSL://kafka-0:9092,OUTBOUND://localhost:19092
      KAFKA_SSL_KEYSTORE_FILENAME: kafka-0.keystore.jks
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka-0.truststore.jks
      KAFKA_SSL_KEYSTORE_PASSWORD: your-password
      KAFKA_SSL_KEY_PASSWORD: your-password
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-0_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-0_sslkey_creds
    networks:
      - kafka-connect-network

  kafka-1:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-1
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    volumes:
      - ./credentials/kafka-1-creds:/etc/kafka/secrets
      - ./credentials/kafka_server_jaas.conf:/etc/kafka/config/kafka_server_jaas.conf
      - ./credentials/admin.properties:/etc/kafka/secrets/admin.properties
    environment:
      <<: *kafka-common-env
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_LISTENERS: SASL_SSL://kafka-1:9092,OUTBOUND://localhost:29092
      KAFKA_SSL_KEYSTORE_FILENAME: kafka-1.keystore.jks
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka-1.truststore.jks
      KAFKA_SSL_KEYSTORE_PASSWORD: your-password
      KAFKA_SSL_KEY_PASSWORD: your-password
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-1_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-1_sslkey_creds
    networks:
      - kafka-connect-network

  kafka-2:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-2
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "39092:39092"
    volumes:
      - ./credentials/kafka-2-creds:/etc/kafka/secrets
      - ./credentials/kafka_server_jaas.conf:/etc/kafka/config/kafka_server_jaas.conf
      - ./credentials/admin.properties:/etc/kafka/secrets/admin.properties
    environment:
      <<: *kafka-common-env
      KAFKA_BROKER_ID: 2
      KAFKA_ADVERTISED_LISTENERS: SASL_SSL://kafka-2:9092,OUTBOUND://localhost:39092
      KAFKA_SSL_KEYSTORE_FILENAME: kafka-2.keystore.jks
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka-2.truststore.jks
      KAFKA_SSL_KEYSTORE_PASSWORD: your-password
      KAFKA_SSL_KEY_PASSWORD: your-password
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-2_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-2_sslkey_creds
    networks:
      - kafka-connect-network

  # --- SCHEMA REGISTRY ---
  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.4
    container_name: schema-registry
    hostname: schema-registry
    depends_on:
      - kafka-0
      - kafka-1
      - kafka-2
    ports:
      - "18081:8081"
    volumes:
      - ./credentials/kafka-0-creds:/etc/kafka/secrets:ro
      - ./credentials/schema-registry.jaas.conf:/etc/schema-registry/secrets/schema-registry.jaas.conf:ro
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry

      # Подключение к Kafka
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: SASL_SSL://kafka-0:9092,SASL_SSL://kafka-1:9092,SASL_SSL://kafka-2:9092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_SSL
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: PLAIN

      # SSL настройки
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka-0.truststore.jks
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_PASSWORD: your-password

      # Вместо файла используем прямую конфигурацию
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="your-password";'

      # Дополнительные настройки
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_DEBUG: 'true'

      # Увеличим таймауты для подключения
      SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT: 30000
      SCHEMA_REGISTRY_KAFKASTORE_TIMEOUT: 30000
    networks:
      - kafka-connect-network
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-0:9092,kafka-1:9092,kafka-2:9092
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_SSL
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: PLAIN
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: >-
        org.apache.kafka.common.security.plain.PlainLoginModule required
        username="admin"
        password="your-password";
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka-0.truststore.jks
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD: your-password
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

      # Добавляем конфигурацию для Schema Registry в Kafka-UI
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    volumes:
      - ./credentials/kafka-0-creds:/etc/kafka/secrets
    depends_on:
      - kafka-0
      - kafka-1
      - kafka-2
      - schema-registry
    networks:
      - kafka-connect-network

  # --- MIRRORMAKER DESTINATION CLUSTER --- (без безопасности, для HDFS)
  zookeeper-destination:
    image: confluentinc/cp-zookeeper:7.4.4
    container_name: zookeeper-destination
    hostname: zookeeper-destination
    environment:
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-connect-network

  kafka-0-destination:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-0-destination
    hostname: kafka-0-destination
    ports:
      - "49092:29093"  # PLAINTEXT_HOST → внешний доступ
      - "9095:9095"    # PLAINTEXT → внутренний доступ
    depends_on:
      - zookeeper-destination
    environment:
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-destination:2182'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_BROKER_ID: 3
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9095,PLAINTEXT_HOST://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-0-destination:9095,PLAINTEXT_HOST://localhost:49092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    networks:
      - kafka-connect-network

  kafka-1-destination:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-1-destination
    hostname: kafka-1-destination
    ports:
      - "59092:29093"  # Хост:59092 → Контейнер:29093 (PLAINTEXT_HOST)
      - "9093:9093"    # Хост:9093 → Контейнер:9093 (PLAINTEXT) :cite[1]
    depends_on:
      - zookeeper-destination
    environment:
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-destination:2182'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_BROKER_ID: 4
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1-destination:9093,PLAINTEXT_HOST://localhost:59092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    networks:
      - kafka-connect-network

  kafka-2-destination:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-2-destination
    hostname: kafka-2-destination
    ports:
      - "59093:29093"  # Хост:59093 → Контейнер:29093 (PLAINTEXT_HOST)
      - "9094:9094"    # Хост:9094 → Контейнер:9094 (PLAINTEXT) :cite[1]
    depends_on:
      - zookeeper-destination
    environment:
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-destination:2182'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_BROKER_ID: 5
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9094,PLAINTEXT_HOST://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2-destination:9094,PLAINTEXT_HOST://localhost:59093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    networks:
      - kafka-connect-network

  schema-registry-destination:
    image: confluentinc/cp-schema-registry:7.4.4
    container_name: schema-registry-destination
    hostname: schema-registry-destination
    depends_on:
      - kafka-0-destination
      - kafka-1-destination
      - kafka-2-destination
    ports:
      - "18082:8084"  # Используйте другой порт, чтобы избежать конфликта с основным Schema Registry
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-destination
      # Подключение к целевому кластеру Kafka
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-0-destination:9095,PLAINTEXT://kafka-1-destination:9093,PLAINTEXT://kafka-2-destination:9094
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT  # Целевой кластер использует PLAINTEXT
      # Дополнительные настройки
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8084
      SCHEMA_REGISTRY_DEBUG: 'true'
      SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT: 30000
      SCHEMA_REGISTRY_KAFKASTORE_TIMEOUT: 30000
      # Уникальный group.id для изоляции кластеров :cite[1]:cite[3]
      SCHEMA_REGISTRY_KAFKASTORE_GROUP_ID: schema-registry-destination-group
      # Уникальное имя темы для хранения схем :cite[1]
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas_destination
    networks:
      - kafka-connect-network
    restart: unless-stopped

  # --- MIRRORMAKER SERVICE ---
  mirror-maker:
    image: confluentinc/cp-kafka:7.4.4
    container_name: mirror-maker
    volumes:
      - ./config/mirror-consumer.properties:/etc/kafka/mirror-consumer.properties
      - ./config/mirror-producer.properties:/etc/kafka/mirror-producer.properties
      - ./credentials/kafka-0-creds:/etc/kafka/secrets:ro
    command: >
      bash -c "
          echo 'Starting MirrorMaker for ALL topics...' &&
          kafka-mirror-maker --consumer.config /etc/kafka/mirror-consumer.properties --producer.config /etc/kafka/mirror-producer.properties --whitelist '.*' --num.streams 3
        "
    depends_on:
      - kafka-0
      - kafka-1
      - kafka-2
      - kafka-0-destination
      - kafka-1-destination
      - kafka-2-destination
    networks:
      - kafka-connect-network

  kafka-ui-destination:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui-destination
    ports:
      - "8082:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: destination-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-0-destination:9095,kafka-1-destination:9093,kafka-2-destination:9094
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
      # Добавьте конфигурацию для целевого Schema Registry
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry-destination:8084
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper-destination:2182
    networks:
      - kafka-connect-network
    depends_on:
      - kafka-0-destination
      - kafka-1-destination
      - kafka-2-destination
      - schema-registry-destination

  # --- HADOOP CLUSTER ---
  hadoop-namenode:
    image: apache/hadoop:3.3.6
    container_name: hadoop-namenode
    environment:
      - HADOOP_HEAPSIZE=2048  # Увеличьте с стандартных 1024MB до 2048MB или больше
      - HADOOP_NAMENODE_OPTS=-Xmx2048m -Xms2048m
      - HADOOP_OPTS=-XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xms2048m -Xmx2048m
    hostname: hadoop-namenode
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "2g"
    shm_size: 10G
    ports:
      - "9870:9870"  # HTTP-порт для Web UI HDFS NameNode
      - "9000:9000"  # RPC порт для запросов к NameNode
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-namenode.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./scripts/namenode_entrypoint.sh:/namenode_entrypoint.sh
    entrypoint: ["/bin/bash", "/namenode_entrypoint.sh"]
    command: ["hdfs", "namenode"]
    networks:
      kafka-connect-network:
      kafka-cluster-network:

  hadoop-datanode-1:
    image: apache/hadoop:3.3.6
    container_name: hadoop-datanode-1
    hostname: hadoop-datanode-1
    user: "root"
    restart: always
    platform: linux/amd64
    ports:
      - "9863:9863"  # Web UI порт для DataNode-1 :cite[10]
      - "9866:9866"  # Data transfer порт для DataNode-1 :cite[10]
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-datanode-1.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./scripts/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: [ "/bin/bash", "/datanode_entrypoint.sh" ]
    command: [ "hdfs", "datanode" ]
    networks:
      kafka-connect-network:
      kafka-cluster-network:

  hadoop-datanode-2:
    image: apache/hadoop:3.3.6
    container_name: hadoop-datanode-2
    hostname: hadoop-datanode-2
    user: "root"
    restart: always
    platform: linux/amd64
    ports:
      - "9865:9865"  # Web UI порт для DataNode-2 :cite[10]
      - "9871:9871"  # Data transfer порт для DataNode-2 :cite[10]
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-datanode-2.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./scripts/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: [ "/bin/bash", "/datanode_entrypoint.sh" ]
    command: [ "hdfs", "datanode" ]
    networks:
      kafka-connect-network:
      kafka-cluster-network:

  hadoop-datanode-3:
    image: apache/hadoop:3.3.6
    container_name: hadoop-datanode-3
    hostname: hadoop-datanode-3
    user: "root"
    restart: always
    platform: linux/amd64
    ports:
      - "9864:9864"  # Web UI порт для DataNode-3 :cite[10]
      - "9868:9868"  # Data transfer порт для DataNode-3 :cite[10]
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-datanode-3.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./scripts/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: [ "/bin/bash", "/datanode_entrypoint.sh" ]
    command: [ "hdfs", "datanode" ]
    networks:
      kafka-connect-network:
      kafka-cluster-network:

  # --- KAFKA CONNECT с HDFS SINK ---
  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.7.1
    extra_hosts:
      - "namenode:172.19.0.8"
    build:
      context: .
      dockerfile: docker/Dockerfile-kafka-connect
    container_name: kafka-connect
    hostname: kafka-connect
    depends_on:
      - kafka-0
      - kafka-1
      - kafka-2
      - schema-registry
      - kafka-0-destination
      - kafka-1-destination
      - kafka-2-destination
      - schema-registry-destination
      - hadoop-namenode
    ports:
      - "18083:8083"
      - "9876:9876"   # Добавьте эту строку для JMX метрик :cite[1]:cite[2]
    environment:
      # Основные настройки Connect
      CONNECT_GROUP_ID: kafka-connect-cluster
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3

      # Настройки для ОСНОВНОГО кластера
      CONNECT_BOOTSTRAP_SERVERS: SASL_SSL://kafka-0:9092,SASL_SSL://kafka-1:9092,SASL_SSL://kafka-2:9092
      CONNECT_SECURITY_PROTOCOL: SASL_SSL
      CONNECT_SASL_MECHANISM: PLAIN
      CONNECT_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="your-password";'
      CONNECT_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka-0.truststore.jks
      CONNECT_SSL_TRUSTSTORE_PASSWORD: your-password

      # Конвертеры для основного кластера
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

      # Настройки для ЦЕЛЕВОГО кластера (HDFS Sink)
      CONNECT_PRODUCER_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-0-destination:9095,PLAINTEXT://kafka-1-destination:9093,PLAINTEXT://kafka-2-destination:9094
      CONNECT_PRODUCER_SECURITY_PROTOCOL: PLAINTEXT
      CONNECT_PRODUCER_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_PRODUCER_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PRODUCER_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry-destination:8084
      CONNECT_PRODUCER_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry-destination:8084

      KAFKA_OPTS: "-javaagent:/opt/jmx_prometheus_javaagent-0.15.0.jar=9876:/opt/kafka-connect.yml"
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_HTTP_REQUEST_TIMEOUT_MS: 120000
      HADOOP_CONF_DIR: /etc/hadoop/conf
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/usr/share/filestream-connectors"
    volumes:
      - ./config/core-site.xml:/etc/hadoop/conf/core-site.xml:ro
      - ./config/hdfs-site-namenode.xml:/etc/hadoop/conf/hdfs-site.xml:ro
      - ./credentials/kafka-0-creds:/etc/kafka/secrets:ro
      - ./data/connector-output:/data/output
      - ./lib/confluent-hub-components:/usr/share/confluent-hub-components
      - ./config/kafka-connect.yml:/opt/kafka-connect.yml:ro  # Монтируем конфиг JMX Exporter
      - ./lib/jmx_prometheus_javaagent-0.15.0.jar:/opt/jmx_prometheus_javaagent-0.15.0.jar:ro # Монтируем JAR агента
    networks:
      - kafka-connect-network
    restart: unless-stopped
  # --- SPARK CLUSTER ---
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8085:8080"  # Spark Web UI
      - "7077:7077"  # Spark Master port
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./config/core-site.xml:/etc/hadoop/conf/core-site.xml:ro
      - ./config/hdfs-site-namenode.xml:/etc/hadoop/conf/hdfs-site.xml:ro
      - ./config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark-apps:/opt/spark-apps
      - ./ssl/client:/kafka-client-creds:ro
    depends_on:
      - hadoop-namenode
      - hadoop-datanode-1
      - hadoop-datanode-2
      - hadoop-datanode-3
    networks:
      - kafka-cluster-network

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./config/core-site.xml:/etc/hadoop/conf/core-site.xml:ro
      - ./config/hdfs-site-namenode.xml:/etc/hadoop/conf/hdfs-site.xml:ro
      - ./config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    depends_on:
      - spark-master
      - hadoop-namenode
    networks:
      - kafka-cluster-network

  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYMPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./config/core-site.xml:/etc/hadoop/conf/core-site.xml:ro
      - ./config/hdfs-site-namenode.xml:/etc/hadoop/conf/hdfs-site.xml:ro
      - ./config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./ssl/client:/kafka-client-creds:ro
    depends_on:
      - spark-master
      - hadoop-namenode
    networks:
      - kafka-cluster-network

  prometheus:
    image: prom/prometheus:v2.30.3
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml
    command: --web.enable-lifecycle --config.file=/etc/prometheus/prometheus.yml
    links:
      - kafka-connect
      - alertmanager
    networks:
      - kafka-connect-network

  alertmanager:
    image: prom/alertmanager:v0.24.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - kafka-connect-network
    depends_on:
      - prometheus

  grafana:
    build:
      context: ./monitoring/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    networks:
      - kafka-connect-network

volumes:
  hadoop_namenode_data:
    driver: local
  hadoop_datanode_data_1:
    driver: local
  hadoop_datanode_data_2:
    driver: local
  hadoop_datanode_data_3:
    driver: local
  kafka_connect_plugins:
    driver: local

networks:
  kafka-connect-network:
    name: kafka-connect-network
  kafka-cluster-network:
    name: kafka_cluster_network